{
 "metadata": {
  "name": "",
  "signature": "sha256:9611ba51fe0913c5183596acb974e5012396effb7b4ec25e3b5bbbf88659ed04"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Extract features from timelines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO:\n",
      "- for frame_to_dict function build to sub functions: events_to_dict, participantsFrame_to_dict; combine both dicts in to_dict\n",
      "- rewrite frame_to_dict to except as parameter the frame from on timestamp before and add \"sum_of_dragons_100|200\" feature and use reduce in match_to_dataset instead of [ for ...]\n",
      "- Check if there can be more extracted from the participantFrames\n",
      "- Extract more event features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os \n",
      "import numpy as np\n",
      "import json\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_team_memberids(match, reference_teamId=100):\n",
      "    \"\"\" \n",
      "    Return a dictionary with participant -> team\n",
      "    \"\"\"\n",
      "    return [x[\"participantId\"] for x in match[\"participants\"] if  x[\"teamId\"] == 100]\n",
      "\n",
      "\n",
      "def get_winner(match, reference_teamId=100):\n",
      "    \"\"\"\n",
      "    Extract id of winning team\n",
      "    \"\"\"\n",
      "    return filter(lambda x: x[\"teamId\"] == reference_teamId, match[\"teams\"])[0][\"winner\"]\n",
      "\n",
      "\n",
      "\n",
      "def filter_events(events, event_type, filter_fun=lambda x: x):\n",
      "    \"\"\"\n",
      "    INPUT: \n",
      "        events: from game frame\n",
      "        event_type: that should be filtered and returned\n",
      "        filter_fun: additional filter function for the events\n",
      "    \"\"\"\n",
      "    return filter(lambda x: x[\"eventType\"] == event_type and filter_fun(x), events)\n",
      "\n",
      "\n",
      "def filter_team_events(events, team, team_100, id_field=\"killerId\"):\n",
      "    if team == 100:\n",
      "        player_ids = team_100\n",
      "    else:\n",
      "        player_ids = np.setdiff1d(range(1, 10), team_100)\n",
      "    return [event for event in events if event[id_field] in player_ids]\n",
      "\n",
      "\n",
      "def frame_events_to_dict(events, team_100):\n",
      "    \"\"\"\n",
      "    Extract features from the events, which contain neutral objectives, kill, shopping and lots more\n",
      "    \"\"\"\n",
      "    results = {}\n",
      "    \n",
      "    dragon_kill = filter_events(events, u'ELITE_MONSTER_KILL', lambda x: x[u'monsterType'] ==  u\"DRAGON\")\n",
      "    \n",
      "    dragon_100 = len(filter_team_events(dragon_kill, 100, team_100))\n",
      "    dragon_200 = len(filter_team_events(dragon_kill, 200, team_100))\n",
      "\n",
      "    results.setdefault(\"dragon_kill_100\", dragon_100)\n",
      "    results.setdefault(\"dragon_kill_200\", dragon_200)\n",
      "        \n",
      "    champion_kills = filter_events(events, 'CHAMPION_KILL') \n",
      "    results.setdefault(\"champion_kill_100\", len(filter_team_events(champion_kills, 100, team_100)))\n",
      "    results.setdefault(\"champion_kill_200\", len(filter_team_events(champion_kills, 200, team_100)))\n",
      "\n",
      "\n",
      "    building_kills = filter_events(events, \"BUILDING_KILL\")\n",
      "    \n",
      "    if len(building_kills) > 0:\n",
      "        building_kills_100 = len(filter_team_events(building_kills, 100, team_100))\n",
      "        building_kills_200 = len(filter_team_events(building_kills, 200, team_100))\n",
      "\n",
      "        inner_kills_100 = len([kill for kill in building_kills if (kill[\"towerType\"] == u'INNER_TURRET' and  kill[\"killerId\"] in team_100)])\n",
      "        inner_kills_200 = len([kill for kill in building_kills if (kill[\"towerType\"] == u'INNER_TURRET' and kill[\"killerId\"] not in team_100)])\n",
      "        inhibitor_kills_100 =  len([kill for kill in building_kills if (kill['buildingType'] == u'INHIBITOR_BUILDING' and kill[\"killerId\"] in team_100)])\n",
      "        inhibitor_kills_200 =  len([kill for kill in building_kills if (kill['buildingType'] == u'INHIBITOR_BUILDING' and kill[\"killerId\"] not in team_100)])\n",
      "\n",
      "        results.setdefault(\"building_kill_100\", building_kills_100)\n",
      "        results.setdefault(\"building_kill_200\", building_kills_200)\n",
      "        results.setdefault(\"kill_inner_100\", inner_kills_100)\n",
      "        results.setdefault(\"kill_inner_200\", inner_kills_200)\n",
      "        results.setdefault(\"kill_inhibitor_100\", inhibitor_kills_100)\n",
      "        results.setdefault(\"kill_inhibitor_200\", inhibitor_kills_200)\n",
      "\n",
      "\n",
      "        \n",
      "    return results\n",
      "\n",
      "def frame_participant_to_dict(pframes, team_100):\n",
      "    \"\"\"\n",
      "    Extract features from the participantFrames, which contain gold, minionkills, junglekills, level\n",
      "    \"\"\"\n",
      "    pframes_100 = [v for k, v in pframes.iteritems() if int(k) in team_100]\n",
      "    pframes_200 = [v for k, v in pframes.iteritems() if int(k) not in team_100]\n",
      "        \n",
      "    sum_of_gold_100 = np.sum([x[\"totalGold\"] for x in pframes_100])\n",
      "    sum_of_gold_200 = np.sum([x[\"totalGold\"] for x in pframes_200])\n",
      "    \n",
      "    level_max_100 = max(x[\"level\"] for x in pframes_100)\n",
      "    level_max_200 = max(x[\"level\"] for x in pframes_200)\n",
      "    level_sum_100 = np.sum(x[\"level\"] for x in pframes_100)\n",
      "    level_sum_200 = np.sum(x[\"level\"] for x in pframes_200)\n",
      "    \n",
      "    result =  {\"gold_100\": sum_of_gold_100, \"gold_200\": sum_of_gold_200, \"level_max_100\": level_max_100, \"level_max_200\": level_max_200, \n",
      "               \"level_sum_100\": level_sum_100, \"level_sum_200\": level_sum_200}\n",
      "    return result\n",
      "\n",
      "def frame_to_dict(frame, match_dict, team_100):\n",
      "    \"\"\"\n",
      "    Extract one frame from the timeline(frames) and build features and add label\n",
      "    INPUT: \n",
      "        frame is one frame of the timeline\n",
      "        match_dict is a dictionary with the label and features that are the same for the whole match\n",
      "        team_100 is the list of ids for member of team with id of 100\n",
      "    OUTPUT: \n",
      "        dictionairy with label and features for one frame\n",
      "    \"\"\"\n",
      "    participants_dict = frame_participant_to_dict(frame[\"participantFrames\"], team_100)\n",
      "    if \"events\" in frame:\n",
      "        events_dict = frame_events_to_dict(frame[\"events\"], team_100)\n",
      "    else:\n",
      "        events_dict = {}\n",
      "    \n",
      "\n",
      "    timestamp = {\"timestamp\": frame[\"timestamp\"] / 60000}\n",
      "    return dict(timestamp.items() + match_dict.items() + participants_dict.items() + events_dict.items())\n",
      "\n",
      "\n",
      "def match_to_dataset(match):\n",
      "    team_100 = get_team_memberids(match)\n",
      "    winner_100 =  get_winner(match)\n",
      "    match_dict = {\"winner_100\": winner_100, \"matchId\": match[\"matchId\"]}\n",
      "    ## first frame is not informative\n",
      "    frames = match[\"timeline\"][\"frames\"][1:]\n",
      "    dataset = [frame_to_dict(frame=frame, match_dict=match_dict, team_100=team_100) for frame in frames]\n",
      "    return dataset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load raw timelines from disk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Load timelines from disk to memory\n",
      "timelines_dir = \"../data/timelines/\"\n",
      "## Loop over timelines and extract features\n",
      " \n",
      "def read_timeline(filename):\n",
      "    fname = timelines_dir + fn\n",
      "    with open(fname) as f:\n",
      "        match = json.load(f)\n",
      "    return match\n",
      "\n",
      "timelines_json = [read_timeline(fn) for fn in os.listdir(timelines_dir)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Compute the features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_rows =  [match_to_dataset(timeline) for timeline in timelines_json if \"timeline\" in timeline]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_rows_flattened = [item for sublist in data_rows for item in sublist]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timelines_df = pd.DataFrame(data_rows_flattened)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timelines_df.to_csv(\"../data/timelines_df.csv\", index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}